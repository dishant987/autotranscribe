# EduVid AI - Video Learning Platform

Transform your lecture videos into interactive learning experiences with automatic transcription and MCQ generation.

## ğŸ“½ï¸ Demo Video

Watch a demo of EduVid AI in action:  
[â–¶ï¸ View Demo on Google Drive](https://drive.google.com/file/d/18IYgCc_9wDg34_NDoy31_ofv_91kqwwc/view?usp=drive_link)

## ğŸš€ Features

- **Video Upload**: Support for MP4 video files up to 300MB
- **Automatic Transcription**: Convert speech to text using Whisper AI
- **Smart Segmentation**: Break videos into 5-minute segments for better navigation
- **MCQ Generation**: AI-powered multiple-choice question creation
- **User Authentication**: Secure login and registration system
- **Dashboard**: Manage all your videos and generated content
- **Export Functionality**: Download transcripts and MCQs
- **Responsive Design**: Works seamlessly on desktop and mobile

## ğŸ“ Project Structure

```
eduvid-ai/
â”œâ”€â”€ client/                    # Frontend (React + TypeScript)
â”‚   â”œâ”€â”€ public/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/         # Reusable UI components
â”‚   â”‚   â”‚   â”œâ”€â”€ ui/            # shadcn/ui components
â”‚   â”‚   â”‚   â”œâ”€â”€ layout.tsx     # Main layout wrapper
â”‚   â”‚   â”‚   â”œâ”€â”€ navbar.tsx     # Navigation component
â”‚   â”‚   â”‚   â””â”€â”€ footer.tsx     # Footer component
â”‚   â”‚   â”œâ”€â”€ pages/             # Page components
â”‚   â”‚   â”‚   â”œâ”€â”€ home.tsx       # Landing page
â”‚   â”‚   â”‚   â”œâ”€â”€ upload.tsx     # Video upload page
â”‚   â”‚   â”‚   â”œâ”€â”€ dashboard.tsx  # User dashboard
â”‚   â”‚   â”‚   â”œâ”€â”€ results.tsx    # Video results page
â”‚   â”‚   â”‚   â”œâ”€â”€ login.tsx      # Login page
â”‚   â”‚   â”‚   â””â”€â”€ signup.tsx     # Registration page
â”‚   â”‚   â”œâ”€â”€ context/           # React contexts
â”‚   â”‚   â”‚   â””â”€â”€ AuthContext.tsx # Authentication context
â”‚   â”‚   â”œâ”€â”€ lib/               # Utility functions
â”‚   â”‚   â””â”€â”€ contents/          # Configuration files
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ vite.config.ts
â”‚
â”œâ”€â”€ server/                    # Backend (Node.js + Express)
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ controllers/       # Route controllers
â”‚   â”‚   â”‚   â”œâ”€â”€ authController.ts    # Authentication logic
â”‚   â”‚   â”‚   â””â”€â”€ videoController.ts   # Video processing logic
â”‚   â”‚   â”œâ”€â”€ middleware/        # Express middleware
â”‚   â”‚   â”‚   â””â”€â”€ authMiddleware.ts    # JWT authentication
â”‚   â”‚   â”œâ”€â”€ models/            # Database models
â”‚   â”‚   â”‚   â”œâ”€â”€ User.ts        # User schema
â”‚   â”‚   â”‚   â””â”€â”€ Video.ts       # Video schema
â”‚   â”‚   â”œâ”€â”€ routes/            # API routes
â”‚   â”‚   â”‚   â”œâ”€â”€ authRoutes.ts  # Authentication routes
â”‚   â”‚   â”‚   â””â”€â”€ videoRoutes.ts # Video routes
â”‚   â”‚   â”œâ”€â”€ utils/             # Utility functions
â”‚   â”‚   â”‚   â”œâ”€â”€ transcription.ts     # Whisper integration
â”‚   â”‚   â”‚   â””â”€â”€ mcqGenerator.ts      # LLM integration
â”‚   â”‚   â”œâ”€â”€ app.ts             # Express app configuration
â”‚   â”‚   â””â”€â”€ server.ts          # Server entry point
â”‚   â”œâ”€â”€ uploads/               # Temporary file storage
â”‚   â”œâ”€â”€ transcripts/           # Generated transcripts
â”‚   â””â”€â”€ package.json
â”‚
â””â”€â”€ README.md                   # This file
```

## ğŸ› ï¸ Tech Stack

### Frontend (client)
- **React 19** with TypeScript
- **Vite** for build tooling
- **Tailwind CSS** for styling
- **shadcn/ui** for UI components
- **React Router** for navigation
- **Framer Motion** for animations
- **Axios** for API calls
- **Sonner** for notifications

### Backend (server2)
- **Node.js** with Express
- **TypeScript** for type safety
- **MongoDB** with Mongoose
- **JWT** for authentication
- **Multer** for file uploads
- **Whisper AI** for transcription
- **Ollama/LLaMA** for MCQ generation

## ğŸ“‹ Prerequisites

Before running this project, make sure you have the following installed:

- **Node.js** (v18 or higher)
- **MongoDB** (local or cloud instance)
- **Python** (for Whisper AI)
- **FFmpeg** (for video processing)
- **Whisper AI** (`pip install openai-whisper`)
- **Ollama** (for LLM integration)

## ğŸš€ Installation & Setup

### 1. Clone the Repository

```bash
git clone https://github.com/yourusername/eduvid-ai.git
cd eduvid-ai
```

### 2. Backend Setup (server)

```bash
cd server
npm install
```

Create a `.env` file in the `server` directory:

```env
PORT=5000
LLM_API_URL=http://127.0.0.1:11434/api/generate
MONGO_URI=mongodb://127.0.0.1:27017/videoqa
JWT_SECRET=your_super_secret_jwt_key_here
```

Create required directories:

```bash
mkdir uploads transcripts
```

Start the backend server:

```bash
npm run dev
```

### 3. Frontend Setup (client)

```bash
cd client
npm install
```

Create a `.env` file in the `client` directory:

```env
VITE_BACKEND_URL=http://localhost:5000
```

Start the frontend development server:

```bash
npm run dev
```

### 4. Additional Setup

#### Install Whisper AI
```bash
pip install openai-whisper
```

#### Install and Setup Ollama
1. Download Ollama from [https://ollama.ai](https://ollama.ai)
2. Install the LLaMA model:
```bash
ollama pull llama3
```
3. Start Ollama server:
```bash
ollama serve
```

#### Install FFmpeg
- **Windows**: Download from [https://ffmpeg.org](https://ffmpeg.org) and add to PATH
- **macOS**: `brew install ffmpeg`
- **Linux**: `sudo apt install ffmpeg`

## ğŸ”§ Configuration

### Environment Variables

#### Backend (.env)
- `PORT`: Server port (default: 5000)
- `MONGO_URI`: MongoDB connection string
- `JWT_SECRET`: Secret key for JWT tokens
- `LLM_API_URL`: Ollama API endpoint

#### Frontend (.env)
- `VITE_BACKEND_URL`: Backend API URL

### File Upload Limits
- Maximum file size: 300MB
- Supported format: MP4 only
- Processing time: Varies based on video length

## ğŸ“– API Documentation

### Authentication Endpoints

#### POST /api/auth/register
Register a new user account.

**Request Body:**
```json
{
  "firstName": "John",
  "lastName": "Doe",
  "email": "john@example.com",
  "password": "password123"
}
```

#### POST /api/auth/login
Login with existing credentials.

**Request Body:**
```json
{
  "email": "john@example.com",
  "password": "password123"
}
```

### Video Endpoints

#### POST /api/video/upload
Upload and process a video file.

**Headers:**
```
Authorization: Bearer <jwt_token>
Content-Type: multipart/form-data
```

**Form Data:**
- `video`: MP4 file (max 300MB)

#### GET /api/video/videos
Get all videos for authenticated user.

#### GET /api/video/:id
Get specific video with transcripts and MCQs.

#### DELETE /api/video/:id
Delete a video and its associated data.

#### PATCH /api/video/:id
Update video filename.

#### GET /api/video/dashboard/data
Get dashboard statistics.

## ğŸ¯ Usage

1. **Register/Login**: Create an account or sign in
2. **Upload Video**: Navigate to upload page and select an MP4 file
3. **Processing**: Wait for automatic transcription and MCQ generation
4. **Review Results**: View transcripts and generated questions
5. **Export Data**: Download transcripts and MCQs as needed
6. **Manage Content**: Use dashboard to organize your videos

## ğŸ”’ Security Features

- JWT-based authentication
- Password hashing with bcrypt
- File type validation
- File size limits
- Protected routes
- Input validation and sanitization

## ğŸš€ Deployment

### Frontend Deployment (Vercel/Netlify)

1. Build the project:
```bash
cd client
npm run build
```

2. Deploy the `dist` folder to your hosting platform

### Backend Deployment (Railway/Heroku)

1. Set environment variables on your hosting platform
2. Ensure MongoDB is accessible
3. Install system dependencies (FFmpeg, Python, Whisper)
4. Deploy the `server` directory

## ğŸ› Known Issues

- Large video files may take significant time to process
- Whisper AI requires substantial system resources
- LLM responses may occasionally need manual review


## ğŸ™ Acknowledgments

- [OpenAI Whisper](https://github.com/openai/whisper) for transcription
- [Ollama](https://ollama.ai) for LLM integration
- [shadcn/ui](https://ui.shadcn.com) for UI components
- [Tailwind CSS](https://tailwindcss.com) for styling

---

**Made with â¤ï¸ by Dishant**
```

This README provides comprehensive documentation for your EduVid AI project, including:

1. **Clear project overview** with features and tech stack
2. **Detailed folder structure** explaining the organization
3. **Step-by-step installation** instructions for both frontend and backend
4. **Configuration details** for environment variables and dependencies
5. **API documentation** with request/response examples
6. **Usage instructions** for end users
7. **Deployment guidelines** for production

```